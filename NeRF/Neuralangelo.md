# Neuralangelo
> High-Fidelity Neural Surface Reconstruction
> CVPR 2023


## 贡献
- 将多分辨率哈希编码的表示能力引入神经 SDF 表示
- 计算高阶导数的数值梯度用于平滑操作
- 对不同细节级别的哈希网格进行从粗到细的优化


## 问题
- 神经表面重建方法：重建的保真度并不能很好地随 MLP 的容量进行扩展，即内存占用增加，重建效果不一定更好
- 需要点云、深度作为辅助数据


## 方法

### 1. 数值梯度计算
#### 数值梯度 & 解析梯度
数值梯度（Numerical gradient）和解析梯度（Analytical gradient）都是计算梯度的方法，用于优化算法中的参数更新。

- 数值梯度：数值梯度是通过使用数值逼近方法计算出的梯度。它基于有限差分近似来估计梯度的值。具体而言，数值梯度会微调参数的一个维度，然后观察损失函数的变化，并计算相应维度上的梯度值。数值梯度的计算方法比较直观，但相对较慢，因为需要对每个参数维度进行两次损失函数计算。由于数值逼近存在舍入误差和计算复杂性，数值梯度可能不够精确，特别是在高维参数空间中。

- 解析梯度：解析梯度是通过应用导数规则和链式法则，以解析形式计算出的梯度。它是直接从损失函数的解析表达式中推导出来的。解析梯度的计算通常更快且更准确，尤其是在高维参数空间中。因为它避免了数值近似带来的误差，同时可以利用已知的函数和导数性质。

#### 计算过程
使用解析梯度的哈希编码具有局部性，所以 Neuralangelo 使用数值梯度来计算表面法线。

如果数值梯度的步长小于哈希编码的网格大小，则数值梯度等效于解析梯度；否则，多个网格单元的哈希项通过表面法线的反向传播，允许多个网格的哈希条目同时进行优化更新。直观地说，数值梯度可以解释为对解析梯度表达式的平滑操作。

为了使用数值梯度计算表面法线，需要额外的 SDF 样本。给定一个采样点 x，在给定步长的范围内，沿着 x 周围坐标的每个轴对两个点进行额外采样，总共需要 6 个额外的 SDF 样本。


### 2. 渐进式细节级别（Progressive Levels of Details）
Neuralangelo 采用了一种从粗到精的优化方案，通过渐进的细节层次来重建表面。对高阶导数使用数值梯度使 Neuralangelo 能够从两个角度进行从粗到精的优化。

- 步长：数值梯度可以解释为平滑操作，其中步长控制分辨率和重建细节的数量。在实验中，首先将步长初始化为最粗的哈希网格大小，并在整个优化过程中匹配不同的哈希网格大小，以指数方式减小步长。

- 哈希网格分辨率：只启用一组初始的粗散列网格，整个优化过程中，在步长减小到空间大小时，逐步激活更细的散列网格。这样可以避免重新学习的过程，可以更好地捕捉细节。在实验中，还对所有参数应用权重衰减，以避免单分辨率特征主导最终结果。
